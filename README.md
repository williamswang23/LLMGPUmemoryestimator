# LLMGPUmemoryestimator
Estimate the GPU memory required for LLM.

This Python script calculates the GPU memory (VRAM) requirements for running inference on a Large Language Model (LLM) based on the number of parameters and the precision of the model. It is designed to provide an estimate to help users plan the hardware resources needed for deploying LLMs.
